{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to statistical NLP with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Chris Potts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Set-up](#Set-up)\n",
    "1. [Data readers](#Data-readers)\n",
    "1. [Feature functions](#Feature-functions)\n",
    "1. [Vectorizing](#Vectorizing)\n",
    "1. [Classifier training](#Classifier-training)\n",
    "1. [Test-set assessment](#Test-set-assessment)\n",
    "1. [Cross-validation](#Cross-validation)\n",
    "1. [Bake-off](#Bake-off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cheese_disease_iterator(filename):\n",
    "    with open(filename, encoding='utf8') as f:\n",
    "        for label, text in csv.reader(f, delimiter='\\t'):\n",
    "            label = 'cheese' if label == '1' else 'disease'\n",
    "            yield text, label\n",
    "            \n",
    "def train_iterator(filename=os.path.join('data', 'cheeseDisease.train.txt')):   \n",
    "    return _cheese_disease_iterator(filename)\n",
    "   \n",
    "def test_iterator(filename=os.path.join('data', 'cheeseDisease.test.txt')):    \n",
    "    return _cheese_disease_iterator(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many examples do we have of each kind in the train set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average string length of train examples of each kind?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(s):\n",
    "    \"\"\"Represent an example `s` as a count dict.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        The example to process.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict \n",
    "        The keys are feature names, and the values are the feature \n",
    "        values -- int, float, or bool.    \n",
    "    \"\"\"\n",
    "    feats = example_length(s)\n",
    "    feats.update(character_unigrams(s))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_length(s):\n",
    "    return {'LENGTH': len(s)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_unigrams(s):\n",
    "    return Counter(list(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize each train example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a `DictVectorizer`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vectorizer's `fit_transform` to map the feature \n",
    "# dicts to a matrix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of train labels:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a `LogisticRegression` model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `fit` on the training data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other models to try:\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-set assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize each test example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vectorizer's `transform` (NOT `fit_transform`!) to map \n",
    "# the feature dicts to a matrix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions on the new exampless:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of test labels:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `classification_report` to see how we did:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "$$\n",
    "\\begin{array}{c c c }\n",
    "\\textbf{Splits} & \\textbf{Experiment 1} & \\textbf{Experiment 2} & \\textbf{Experiment 3} \\\\\n",
    "\\begin{array}{|c|}\n",
    "\\hline\n",
    "\\textrm{fold } 1  \\\\\\hline\n",
    "\\textrm{fold } 2  \\\\\\hline\n",
    "\\textrm{fold } 3  \\\\\\hline\n",
    "\\end{array}\n",
    "& \n",
    "\\begin{array}{|c c|}\n",
    "\\hline\n",
    "\\textbf{Test} & \\textrm{fold } 1  \\\\\\hline\n",
    "\\textbf{Train} & \\textrm{fold } 2  \\\\\n",
    "& \\textrm{fold } 3  \\\\\\hline\n",
    "\\end{array}\n",
    "&\n",
    "\\begin{array}{|c c|}\n",
    "\\hline\n",
    "\\textbf{Test} & \\textrm{fold } 2  \\\\\\hline\n",
    "\\textbf{Train} & \\textrm{fold } 1  \\\\\n",
    "& \\textrm{fold } 3  \\\\\\hline\n",
    "\\end{array}\n",
    "&\n",
    "\\begin{array}{|c c|}\n",
    "\\hline\n",
    "\\textbf{Test} & \\textrm{fold } 3  \\\\\\hline\n",
    "\\textbf{Train} & \\textrm{fold } 1  \\\\\n",
    "& \\textrm{fold } 2  \\\\\\hline\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    estimator=None,  # Fill this in.\n",
    "    X=None,          # Fill this in.\n",
    "    y=None,          # Fill this in.\n",
    "    cv=cv,\n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bake-off\n",
    "\n",
    "1. The test set is off-limits during development! We will assess on it only once development is complete.\n",
    "\n",
    "1. So, using just cross-validation runs on the train data, design a model that does really well at the cheese-disease task. You can fiddle with the featurizer, the choice of model, and pretty much anything else, as long as you don't look at the test data.\n",
    "\n",
    "1. When you are all done, run the code below, where `your_featurize` is the featurizer you created, `your_vec` is the vectorizer you use, and `your_model` is the model that you developed, and then report the macro-F1 score to Chris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = [your_featurize(text) for text, label in test_iterator()]\n",
    "\n",
    "X_test = your_vec.transform(test_feats)\n",
    "\n",
    "y_test = [label for text, label in test_iterator()]\n",
    "\n",
    "test_preds = your_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
