{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to introduce you to scikit-learn with the help of an instructional example about text classification. We will cover the most basic principles and ideas about scikit-learn in this notebook. This tutorial is inspired by the sklearn tutorial on http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html, but contains a few more explanations and is suited to introduce scikit-learn in class.\n",
    "\n",
    "$Author$: Phillip Str√∂bel (changes by Tilia Ellendorff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Get the data from http://qwone.com/~jason/20Newsgroups/. We will work with the **20news-bydate.tar.gz** data set. - Unzip it to a suitable destination. Here, all the data lies in the data folder. It has already been split into a training and a test set, so we don't have to care about this. What we need to do though is get the data and put it into a dataframe (you could also only work with dictionaries or other data containers). We do this for both the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "def create_df(path_to_data, categories=[], shuffle=True, random_state=42):\n",
    "    \"\"\"\n",
    "    takes the path of a folder containing all the subfolders (which contain the acutal documents). builds a pandas datafram with document ids, the text and the label. shuffled is default.\n",
    "    :param path_to_data: path to top folder as a string\n",
    "    :param categories: categories which should be in the dataframe as list of strings, default is all categories\n",
    "    :param shuffle: boolean, determines whether data should be shuffled or not\n",
    "    :param random_state: integer, seed for shuffling\n",
    "    :return: pandas dataframe with all th\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_list = list()\n",
    "    \n",
    "    if categories == []:\n",
    "        for category in os.listdir(path_to_data):\n",
    "            for document in os.listdir(os.path.join(path_to_data, category)):\n",
    "                doc = codecs.open(os.path.join(path_to_data, category, document), 'r', 'latin-1').read().replace('\\n', ' ')\n",
    "                doc_list.append([doc, category])\n",
    "    else:\n",
    "        for category in categories:\n",
    "            for document in os.listdir(os.path.join(path_to_data, category)):\n",
    "                doc = codecs.open(os.path.join(path_to_data, category, document), 'r', 'latin-1').read().replace('\\n', ' ')\n",
    "                doc_list.append([doc, category])\n",
    "    \n",
    "    df = pd.DataFrame(doc_list, columns=['text', 'label'])\n",
    "\n",
    "    return df.sample(frac=1, random_state=random_state)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tilia/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Desktop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_df('data/20news-bydate/20news-bydate-train')\n",
    "test = create_df('data/20news-bydate/20news-bydate-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:  (11314, 2)\n",
      "test size:  (7532, 2)\n"
     ]
    }
   ],
   "source": [
    "print('training size: ', train.shape)\n",
    "print('test size: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>From: wtm@uhura.neoucom.edu (Bill Mayhew) Subj...</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>From: andy@SAIL.Stanford.EDU (Andy Freeman) Su...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>From: cs1442aq@news.uta.edu (cs1442aq) Subject...</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>From: cjackson@adobe.com (Curtis Jackson) Subj...</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>From: frp@table.NSD.3Com.COM (Frank R. Pereira...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text               label\n",
       "7492  From: wtm@uhura.neoucom.edu (Bill Mayhew) Subj...     sci.electronics\n",
       "3546  From: andy@SAIL.Stanford.EDU (Andy Freeman) Su...        misc.forsale\n",
       "5582  From: cs1442aq@news.uta.edu (cs1442aq) Subject...  rec.sport.baseball\n",
       "4793  From: cjackson@adobe.com (Curtis Jackson) Subj...     rec.motorcycles\n",
       "3813  From: frp@table.NSD.3Com.COM (Frank R. Pereira...        misc.forsale"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first few rows of the dataframe\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11314</td>\n",
       "      <td>11314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11314</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>From: koontzd@phobos.lrmsc.loral.com (David Ko...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text             label\n",
       "count                                               11314             11314\n",
       "unique                                              11314                20\n",
       "top     From: koontzd@phobos.lrmsc.loral.com (David Ko...  rec.sport.hockey\n",
       "freq                                                    1               600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get short overview of frequency measures for the dataframe\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "alt.atheism                 480\n",
       "comp.graphics               584\n",
       "comp.os.ms-windows.misc     591\n",
       "comp.sys.ibm.pc.hardware    590\n",
       "comp.sys.mac.hardware       578\n",
       "comp.windows.x              593\n",
       "misc.forsale                585\n",
       "rec.autos                   594\n",
       "rec.motorcycles             598\n",
       "rec.sport.baseball          597\n",
       "rec.sport.hockey            600\n",
       "sci.crypt                   595\n",
       "sci.electronics             591\n",
       "sci.med                     594\n",
       "sci.space                   593\n",
       "soc.religion.christian      599\n",
       "talk.politics.guns          546\n",
       "talk.politics.mideast       564\n",
       "talk.politics.misc          465\n",
       "talk.religion.misc          377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label distribution\n",
    "\n",
    "train.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the labels from the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.text\n",
    "y_train = train.label\n",
    "X_test = test.text\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we got this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (11314,)\n",
      "Training labels shape:  (11314,)\n",
      "Test set shape:  (7532,)\n",
      "Test labels shape:  (7532,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test set shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7492    From: wtm@uhura.neoucom.edu (Bill Mayhew) Subj...\n",
       "3546    From: andy@SAIL.Stanford.EDU (Andy Freeman) Su...\n",
       "5582    From: cs1442aq@news.uta.edu (cs1442aq) Subject...\n",
       "4793    From: cjackson@adobe.com (Curtis Jackson) Subj...\n",
       "3813    From: frp@table.NSD.3Com.COM (Frank R. Pereira...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Machine learning algorithms cannot work with text data directly. So we need to vectorise the data somehow. Also, we want to do some preprocessing.\n",
    "### Vectorise the data \n",
    "Sklearn offers helpful classes for preprocessing and vectorization: \n",
    "`CountVectoriser()` tokenises the data and then vectorises it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central methods in sklearn are `transform`, `fit`, `fit_transform`, and `predict`. We will see how each of these work and when to use them. We have alredy made use of `fit_transform`. Instead of using this method, we could have called the method `fit` first and the use `transform` to vectorise the data (to 'transform' it). With the fitted `CountVectorizer` we can now also transform the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will return to this later. First let us see what `CountVectorizer` produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorised form contains 11314 rows, which is the number of our documents, while the number of columns tells us something about the vocabulary size of the whole corpus. But what's a sparse matrix? Note that saving the complete, sparse document-vocabulary matrix would need to hold 1,472,030,598 values, most of which would be zero? Why? Instead, we only save 1,787,565 values in a compressed sparse row format. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "mtx = sparse.csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "mtx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 2],\n",
       "        [0, 0, 3],\n",
       "        [4, 5, 6]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 132 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one training example, we can look up which positions of the document vector are occupied. A `1` means the word occurs once in the document (i.e. each number gives the exact count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 85829)\t1\n",
      "  (0, 15599)\t1\n",
      "  (0, 4469)\t1\n",
      "  (0, 8926)\t1\n",
      "  (0, 4156)\t1\n",
      "  (0, 9725)\t1\n",
      "  (0, 11676)\t1\n",
      "  (0, 8861)\t1\n",
      "  (0, 93582)\t1\n",
      "  (0, 119714)\t1\n",
      "  (0, 22455)\t1\n",
      "  (0, 13703)\t1\n",
      "  (0, 89496)\t1\n",
      "  (0, 102933)\t1\n",
      "  (0, 46364)\t1\n",
      "  (0, 106253)\t1\n",
      "  (0, 41614)\t1\n",
      "  (0, 41444)\t1\n",
      "  (0, 106030)\t1\n",
      "  (0, 71079)\t1\n",
      "  (0, 124332)\t1\n",
      "  (0, 47721)\t1\n",
      "  (0, 96346)\t1\n",
      "  (0, 90642)\t1\n",
      "  (0, 119781)\t1\n",
      "  :\t:\n",
      "  (0, 125265)\t1\n",
      "  (0, 9221)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 80816)\t1\n",
      "  (0, 89362)\t6\n",
      "  (0, 40998)\t1\n",
      "  (0, 118981)\t1\n",
      "  (0, 89513)\t1\n",
      "  (0, 87905)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 96493)\t1\n",
      "  (0, 42597)\t2\n",
      "  (0, 47729)\t1\n",
      "  (0, 114455)\t12\n",
      "  (0, 115475)\t6\n",
      "  (0, 64186)\t1\n",
      "  (0, 99721)\t2\n",
      "  (0, 111322)\t1\n",
      "  (0, 80016)\t2\n",
      "  (0, 33331)\t2\n",
      "  (0, 50527)\t2\n",
      "  (0, 86642)\t3\n",
      "  (0, 118043)\t2\n",
      "  (0, 125402)\t2\n",
      "  (0, 56979)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can get the number of words in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[1,:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can count how many times a certain word occurs across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1534"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[:,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find out how many times a specific word occurs in the corpus. First, we need to find the index (i.e. the column in the feature matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38082"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the index, we can count how many times the word \"sin\" occurs in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_index = count_vect.vocabulary_.get(u'cat')\n",
    "X_train_counts[:,sin_index].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer` also lets you also define if you want to count bigrams, or other n-grams. Moreover, you can not only count words, but als characters. We suggest you try these out for yourself. In the following, we will continue with unigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the feature matrix, we have numbers now instead of strings, we could start training models now. However, raw counts will not be very informative: we also have to take the length of a document into account. Dividing each row (= document) by the total number of words (lenght of document) will give us the term frequency for each document. \n",
    "\n",
    "Now we still might have higher values for words which occur often in many documents. typically, these words are less informative, so we need to downscale those weights. This will modify the counts so that we are left with what is called the \"term frequency-inverse document frequency\" measure, or tf-idf. \n",
    "\n",
    "The tf-idf measure is given by\n",
    "\\begin{equation}\n",
    "f_{t,d}\\cdot log \\frac{N}{n_t}\n",
    "\\end{equation}\n",
    "\n",
    "$f_{t,d}$: frequency of the term in the document\n",
    "\n",
    "$N$: total number of documents \n",
    "\n",
    "$n_t$: number of documents containing the term\n",
    "\n",
    "In sklearn, there is the `TfidfTransformer` which does exactly that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_tranformer = TfidfTransformer(smooth_idf=True).fit(X_train_counts)\n",
    "X_train_tfidf = tfidf_tranformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 132 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 128420)\t0.14914751234941234\n",
      "  (0, 128402)\t0.041289967044730036\n",
      "  (0, 125402)\t0.20554387623963322\n",
      "  (0, 125265)\t0.0562179954199715\n",
      "  (0, 124616)\t0.02103567604210259\n",
      "  (0, 124332)\t0.028017219611406446\n",
      "  (0, 119781)\t0.04254598422656834\n",
      "  (0, 119765)\t0.19094533497428623\n",
      "  (0, 119737)\t0.0352226168646674\n",
      "  (0, 119714)\t0.039862967640059414\n",
      "  (0, 119030)\t0.05421354863341172\n",
      "  (0, 118981)\t0.08688388027531756\n",
      "  (0, 118927)\t0.08108687216316744\n",
      "  (0, 118043)\t0.18346167565320634\n",
      "  (0, 115663)\t0.039095267323677414\n",
      "  (0, 115475)\t0.08883517756138443\n",
      "  (0, 114455)\t0.17133945269935724\n",
      "  (0, 114440)\t0.01796797905375421\n",
      "  (0, 112031)\t0.04227573733268885\n",
      "  (0, 111322)\t0.013355977342780002\n",
      "  (0, 111133)\t0.07311158365763981\n",
      "  (0, 108677)\t0.09331388712608685\n",
      "  (0, 108558)\t0.026923971216528297\n",
      "  (0, 107489)\t0.09869326772751025\n",
      "  (0, 106969)\t0.12876146998168503\n",
      "  :\t:\n",
      "  (0, 33331)\t0.10945263414498524\n",
      "  (0, 32941)\t0.04537749159889928\n",
      "  (0, 31495)\t0.04889071156133089\n",
      "  (0, 30278)\t0.09015773027101265\n",
      "  (0, 30044)\t0.02409645479244271\n",
      "  (0, 29241)\t0.021949354130915665\n",
      "  (0, 28952)\t0.06738915337592881\n",
      "  (0, 28146)\t0.03164782962175937\n",
      "  (0, 28012)\t0.050334084559220164\n",
      "  (0, 27618)\t0.03312656007757283\n",
      "  (0, 25641)\t0.09869326772751025\n",
      "  (0, 22455)\t0.10376172251682109\n",
      "  (0, 22110)\t0.0722108394393666\n",
      "  (0, 15599)\t0.09215487272195545\n",
      "  (0, 13703)\t0.10376172251682109\n",
      "  (0, 11676)\t0.09053397986550608\n",
      "  (0, 9725)\t0.10376172251682109\n",
      "  (0, 9221)\t0.05212241580623516\n",
      "  (0, 8926)\t0.08474234747383216\n",
      "  (0, 8861)\t0.08474234747383216\n",
      "  (0, 8266)\t0.04420996255982071\n",
      "  (0, 5466)\t0.04836103710113803\n",
      "  (0, 4605)\t0.04415062893339484\n",
      "  (0, 4469)\t0.08425662204227567\n",
      "  (0, 4156)\t0.07719765143442926\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we apply the transformation to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf_tranformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should suffice as features to train a classifer (for the moment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorise labels\n",
    "Next, we need to encode the labels. Every document has exactly one label attached. We have 20 unique labels in total. This means we can basically assign a number to each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
       "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
       "       'sci.electronics', 'sci.med', 'sci.space',\n",
       "       'soc.religion.christian', 'talk.politics.guns',\n",
       "       'talk.politics.mideast', 'talk.politics.misc',\n",
       "       'talk.religion.misc'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, let's train models\n",
    "Now it's time to train models. Let's stick to the Multinomial Naive Bayes classifier for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well we do on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  8, 16, ..., 15,  2, 18])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  8, 16, ..., 13,  2, 18])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy tp see how the model performs on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7738980350504514\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for index, prediction in enumerate(nb_clf.predict(X_test_tfidf)):\n",
    "    if prediction == y_test[index]:\n",
    "        correct +=1\n",
    "\n",
    "print('Accuracy: ', correct/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 80 percent, that is not too bad. What about a Support Vector Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8531598513011153\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for index, prediction in enumerate(svc.predict(X_test_tfidf)):\n",
    "    if prediction == y_test[index]:\n",
    "        correct +=1\n",
    "\n",
    "print('Accuracy: ', correct/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An increase of 8%, that's good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a more representative measure of performance of our models we can use cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(nb_clf, X_train_tfidf, y_train, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85526316, 0.85852373, 0.83919156, 0.84507042, 0.85335689,\n",
       "       0.85828167, 0.84397163, 0.84813499, 0.84608541, 0.84594835])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(svc, X_train_tfidf, y_train, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93596491, 0.92179262, 0.92618629, 0.92605634, 0.93551237,\n",
       "       0.93002657, 0.92907801, 0.94404973, 0.91992883, 0.91718611])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better impression of model performance calculate precision, recall, and f1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=50,  tol=0.001)\n",
    "sgd_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_train_predictions = cross_val_predict(sgd_clf, X_train_tfidf, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165635495845855\n",
      "0.9165635495845855\n",
      "0.9165635495845854\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_train, y_train_predictions, average='micro'))\n",
    "print(recall_score(y_train, y_train_predictions, average='micro'))\n",
    "print(f1_score(y_train, y_train_predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[439,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   1,  14,   0,   2,   1,  21],\n",
       "       [  0, 499,  12,  16,   7,  20,  10,   1,   0,   2,   1,   1,   7,\n",
       "          4,   4,   0,   0,   0,   0,   0],\n",
       "       [  0,  15, 525,  22,   2,  14,   6,   0,   0,   0,   0,   0,   3,\n",
       "          1,   0,   2,   0,   0,   1,   0],\n",
       "       [  0,  18,  37, 473,  14,   5,  18,   2,   1,   0,   1,   0,  16,\n",
       "          3,   0,   1,   0,   0,   0,   1],\n",
       "       [  0,  10,   5,  20, 511,   3,   8,   0,   4,   3,   0,   1,   8,\n",
       "          2,   1,   0,   1,   0,   1,   0],\n",
       "       [  0,  24,  14,   7,   0, 535,   5,   1,   1,   0,   1,   0,   2,\n",
       "          2,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,   3,   5,  15,   4,   2, 518,  14,   3,   0,   3,   1,   9,\n",
       "          3,   2,   1,   1,   1,   0,   0],\n",
       "       [  0,   4,   1,   3,   2,   1,   8, 546,   8,   4,   2,   0,  11,\n",
       "          0,   2,   0,   1,   0,   1,   0],\n",
       "       [  1,   2,   1,   0,   2,   1,  12,   2, 574,   0,   1,   0,   1,\n",
       "          0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   1,   1,   1,   0,   0,   3,   3,   1, 571,  12,   0,   2,\n",
       "          0,   1,   0,   0,   0,   1,   0],\n",
       "       [  0,   1,   0,   1,   1,   0,   2,   0,   1,   4, 584,   0,   1,\n",
       "          1,   0,   1,   0,   1,   1,   1],\n",
       "       [  0,   3,   1,   1,   0,   3,   0,   1,   0,   0,   0, 578,   2,\n",
       "          0,   1,   2,   1,   2,   0,   0],\n",
       "       [  0,   7,   5,  19,   8,   3,  21,  10,   2,   4,   3,   0, 502,\n",
       "          1,   2,   3,   0,   0,   1,   0],\n",
       "       [  0,   5,   1,   0,   1,   1,   5,   3,   0,   0,   0,   1,   5,\n",
       "        570,   1,   0,   1,   0,   0,   0],\n",
       "       [  0,   4,   0,   1,   1,   1,   3,   0,   0,   0,   0,   0,   1,\n",
       "          2, 577,   0,   1,   1,   1,   0],\n",
       "       [  5,   2,   0,   1,   1,   3,   3,   1,   0,   1,   1,   1,   1,\n",
       "          5,   0, 569,   0,   2,   0,   3],\n",
       "       [  0,   0,   1,   0,   0,   0,   1,   2,   0,   2,   1,   2,   3,\n",
       "          2,   2,   0, 526,   1,   2,   1],\n",
       "       [  1,   2,   0,   0,   0,   1,   1,   0,   0,   1,   0,   0,   0,\n",
       "          0,   1,   3,   0, 554,   0,   0],\n",
       "       [  2,   0,   4,   1,   2,   1,   1,   1,   1,   1,   1,   2,   0,\n",
       "          3,   3,   4,   8,   4, 425,   1],\n",
       "       [ 24,   0,   0,   0,   0,   2,   1,   2,   2,   0,   0,   0,   2,\n",
       "          3,   1,  26,  11,   2,   7, 294]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_train, y_train_predictions)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
       "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
       "       'sci.electronics', 'sci.med', 'sci.space',\n",
       "       'soc.religion.christian', 'talk.politics.guns',\n",
       "       'talk.politics.mideast', 'talk.politics.misc',\n",
       "       'talk.religion.misc'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortcuts in sklearn - pipelines\n",
    "Sklearn allows us to build convenient `Pipelines`, which facilitate the management of our data and the training of our models enourmously. Consider for ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('nb_clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even replace the two first lines of the pipeline by using `TfidfVectorizer`, which first fits and transforms the input the same way as `CountVectorizer` followed by `TfidfTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ar_tf=False, use_idf=True)), ('nb_clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(text_clf, X_train, y_train, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85526316, 0.8602812 , 0.8427065 , 0.8459507 , 0.85689046,\n",
       "       0.8591674 , 0.84485816, 0.84991119, 0.84519573, 0.84861977])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection - find your best model\n",
    "For every model you would like to train, there is a plethora of parameters you could set. How to find the best model? Sklearn has a solution: `GridSearchCV`. \n",
    "\n",
    "With grid search cross validation, you can define your hyperparameter space and train different models with all the parameter combinations. Keep in mind that depending on how many folds you train, the whole training procedure can take significantly longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed: 50.5min finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'svc__loss': ['hinge', 'squared_hinge'], 'svc__multi_class': ['ovr', 'crammer_singer']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_svc = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svc', LinearSVC())\n",
    "])\n",
    "\n",
    "param_grid = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "             'svc__loss': ['hinge', 'squared_hinge'],\n",
    "             'svc__multi_class': ['ovr', 'crammer_singer']}\n",
    "\n",
    "gs_svc = GridSearchCV(text_svc, param_grid, cv=5, n_jobs=4, verbose=1)\n",
    "gs_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/phillip/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_svc__loss</th>\n",
       "      <th>param_svc__multi_class</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>686.134789</td>\n",
       "      <td>3.743508</td>\n",
       "      <td>0.930705</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'svc__loss': 'hinge', 'svc__multi_class': 'cr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924912</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.926991</td>\n",
       "      <td>0.999116</td>\n",
       "      <td>0.934368</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>286.866087</td>\n",
       "      <td>0.126190</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>662.552173</td>\n",
       "      <td>2.885766</td>\n",
       "      <td>0.930705</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'svc__loss': 'squared_hinge', 'svc__multi_cla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924912</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.926991</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>0.934368</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>208.876589</td>\n",
       "      <td>0.894399</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57.669994</td>\n",
       "      <td>3.633046</td>\n",
       "      <td>0.930263</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'svc__loss': 'squared_hinge', 'svc__multi_cla...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.936536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924028</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.923451</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.932151</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>1.424082</td>\n",
       "      <td>0.317880</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339.978553</td>\n",
       "      <td>3.932459</td>\n",
       "      <td>0.928938</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'svc__loss': 'hinge', 'svc__multi_class': 'ov...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926237</td>\n",
       "      <td>0.998232</td>\n",
       "      <td>0.921239</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.930377</td>\n",
       "      <td>0.999007</td>\n",
       "      <td>47.562352</td>\n",
       "      <td>0.643115</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.755919</td>\n",
       "      <td>1.589989</td>\n",
       "      <td>0.924607</td>\n",
       "      <td>0.999138</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'svc__loss': 'squared_hinge', 'svc__multi_cla...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.929925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924912</td>\n",
       "      <td>0.999227</td>\n",
       "      <td>0.915044</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>0.925055</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.882834</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.000190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.151473</td>\n",
       "      <td>1.638614</td>\n",
       "      <td>0.924342</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'svc__loss': 'hinge', 'svc__multi_class': 'ov...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.930366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924028</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>0.913717</td>\n",
       "      <td>0.994478</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.995474</td>\n",
       "      <td>9.684970</td>\n",
       "      <td>0.225647</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.052793</td>\n",
       "      <td>1.491734</td>\n",
       "      <td>0.924076</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'svc__loss': 'hinge', 'svc__multi_class': 'cr...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.929044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922261</td>\n",
       "      <td>0.998674</td>\n",
       "      <td>0.919469</td>\n",
       "      <td>0.998343</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>52.200238</td>\n",
       "      <td>0.116839</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>185.887219</td>\n",
       "      <td>1.562905</td>\n",
       "      <td>0.924076</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'svc__loss': 'squared_hinge', 'svc__multi_cla...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.929044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922261</td>\n",
       "      <td>0.998674</td>\n",
       "      <td>0.919469</td>\n",
       "      <td>0.998343</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>41.081316</td>\n",
       "      <td>0.157256</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3     686.134789         3.743508         0.930705          0.999403   \n",
       "7     662.552173         2.885766         0.930705          0.999359   \n",
       "5      57.669994         3.633046         0.930263          0.999669   \n",
       "1     339.978553         3.932459         0.928938          0.998387   \n",
       "4      12.755919         1.589989         0.924607          0.999138   \n",
       "0      55.151473         1.638614         0.924342          0.995139   \n",
       "2     184.052793         1.491734         0.924076          0.998564   \n",
       "6     185.887219         1.562905         0.924076          0.998564   \n",
       "\n",
       "  param_svc__loss param_svc__multi_class param_vect__ngram_range  \\\n",
       "3           hinge         crammer_singer                  (1, 2)   \n",
       "7   squared_hinge         crammer_singer                  (1, 2)   \n",
       "5   squared_hinge                    ovr                  (1, 2)   \n",
       "1           hinge                    ovr                  (1, 2)   \n",
       "4   squared_hinge                    ovr                  (1, 1)   \n",
       "0           hinge                    ovr                  (1, 1)   \n",
       "2           hinge         crammer_singer                  (1, 1)   \n",
       "6   squared_hinge         crammer_singer                  (1, 1)   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "3  {'svc__loss': 'hinge', 'svc__multi_class': 'cr...                1   \n",
       "7  {'svc__loss': 'squared_hinge', 'svc__multi_cla...                1   \n",
       "5  {'svc__loss': 'squared_hinge', 'svc__multi_cla...                3   \n",
       "1  {'svc__loss': 'hinge', 'svc__multi_class': 'ov...                4   \n",
       "4  {'svc__loss': 'squared_hinge', 'svc__multi_cla...                5   \n",
       "0  {'svc__loss': 'hinge', 'svc__multi_class': 'ov...                6   \n",
       "2  {'svc__loss': 'hinge', 'svc__multi_class': 'cr...                7   \n",
       "6  {'svc__loss': 'squared_hinge', 'svc__multi_cla...                7   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "3           0.937417       ...                  0.924912            0.999558   \n",
       "7           0.937417       ...                  0.924912            0.999448   \n",
       "5           0.936536       ...                  0.924028            0.999669   \n",
       "1           0.934332       ...                  0.926237            0.998232   \n",
       "4           0.929925       ...                  0.924912            0.999227   \n",
       "0           0.930366       ...                  0.924028            0.995359   \n",
       "2           0.929044       ...                  0.922261            0.998674   \n",
       "6           0.929044       ...                  0.922261            0.998674   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "3           0.926991            0.999116           0.934368   \n",
       "7           0.926991            0.999006           0.934368   \n",
       "5           0.923451            0.999558           0.932151   \n",
       "1           0.921239            0.998012           0.930377   \n",
       "4           0.915044            0.999006           0.925055   \n",
       "0           0.913717            0.994478           0.927273   \n",
       "2           0.919469            0.998343           0.926829   \n",
       "6           0.919469            0.998343           0.926829   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "3            0.999669    286.866087        0.126190        0.004619   \n",
       "7            0.999669    208.876589        0.894399        0.004619   \n",
       "5            0.999890      1.424082        0.317880        0.005513   \n",
       "1            0.999007     47.562352        0.643115        0.004697   \n",
       "4            0.999448      0.882834        0.366745        0.005138   \n",
       "0            0.995474      9.684970        0.225647        0.005686   \n",
       "2            0.999117     52.200238        0.116839        0.003420   \n",
       "6            0.999117     41.081316        0.157256        0.003420   \n",
       "\n",
       "   std_train_score  \n",
       "3         0.000193  \n",
       "7         0.000214  \n",
       "5         0.000121  \n",
       "1         0.000332  \n",
       "4         0.000190  \n",
       "0         0.000363  \n",
       "2         0.000313  \n",
       "6         0.000313  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_df = pd.DataFrame.from_dict(gs_svc.cv_results_)\n",
    "svc_df.sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  2, 17, ...,  9,  1,  2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  2, 17, ...,  9,  1,  6])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip...0,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svc', LinearSVC(loss='hinge', multi_class='crammer_singer'))\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  2, 17, ...,  9,  1,  2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8600637280934679\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for index, prediction in enumerate(best_model.predict(X_test)):\n",
    "    if prediction == y_test[index]:\n",
    "        correct +=1\n",
    "\n",
    "print('Accuracy: ', correct/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
