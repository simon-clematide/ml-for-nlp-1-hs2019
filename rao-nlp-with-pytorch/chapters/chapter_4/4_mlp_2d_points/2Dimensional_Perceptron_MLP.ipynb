{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [0, 0, 1, 1]\n",
    "CENTERS = [(-3, -3), (3, 3), (3, -3), (-3, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size=2, output_size=3, \n",
    "                 num_hidden_layers=1, hidden_activation=nn.Sigmoid):\n",
    "        \"\"\"Initialize weights.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): size of the input \n",
    "            hidden_size (int): size of the hidden layers\n",
    "            output_size (int): size of the output\n",
    "            num_hidden_layers (int): number of hidden layers\n",
    "            hidden_activation (torch.nn.*): the activation class\n",
    "        \"\"\"\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        self.module_list = nn.ModuleList()\n",
    "        \n",
    "        interim_input_size = input_size\n",
    "        interim_output_size = hidden_size\n",
    "        \n",
    "        \n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.module_list.append(nn.Linear(interim_input_size, interim_output_size))\n",
    "            self.module_list.append(hidden_activation())\n",
    "            interim_input_size = interim_output_size\n",
    "            \n",
    "        self.fc_final = nn.Linear(interim_input_size, output_size)\n",
    "        \n",
    "        self.last_forward_cache = []\n",
    "       \n",
    "    def forward(self, x, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the MLP\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        self.last_forward_cache = []\n",
    "        self.last_forward_cache.append(x.to(\"cpu\").numpy())\n",
    "\n",
    "        for module in self.module_list:\n",
    "            x = module(x)\n",
    "            self.last_forward_cache.append(x.to(\"cpu\").data.numpy())\n",
    "            \n",
    "        output = self.fc_final(x)\n",
    "        self.last_forward_cache.append(output.to(\"cpu\").data.numpy())\n",
    "\n",
    "        if apply_softmax:\n",
    "            output = F.softmax(output, dim=1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy_data(batch_size):\n",
    "    assert len(CENTERS) == len(LABELS), 'centers should have equal number labels'\n",
    "    \n",
    "    x_data = []\n",
    "    y_targets = np.zeros(batch_size)\n",
    "    n_centers = len(CENTERS)\n",
    "    \n",
    "    for batch_i in range(batch_size):\n",
    "        center_idx = np.random.randint(0, n_centers)\n",
    "        x_data.append(np.random.normal(loc=CENTERS[center_idx]))\n",
    "        y_targets[batch_i] = LABELS[center_idx]\n",
    "        \n",
    "    return torch.tensor(x_data, dtype=torch.float32), torch.tensor(y_targets, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(perceptron, x_data, y_truth, n_samples=1000, ax=None, epoch=None, \n",
    "                      title='', levels=[0.3, 0.4, 0.5], linestyles=['--', '-', '--']):\n",
    "    _, y_pred = perceptron(x_data, apply_softmax=True).max(dim=1)\n",
    "    y_pred = y_pred.data.numpy()\n",
    "\n",
    "    x_data = x_data.data.numpy()\n",
    "    y_truth = y_truth.data.numpy()\n",
    "\n",
    "\n",
    "    n_classes = len(set(LABELS))\n",
    "\n",
    "    all_x = [[] for _ in range(n_classes)]\n",
    "    all_colors = [[] for _ in range(n_classes)]\n",
    "    \n",
    "    colors = ['black', 'white']\n",
    "    markers = ['o', '*']\n",
    "    \n",
    "    for x_i, y_pred_i, y_true_i in zip(x_data, y_pred, y_truth):\n",
    "        all_x[y_true_i].append(x_i)\n",
    "        if y_pred_i == y_true_i:\n",
    "            all_colors[y_true_i].append(\"white\")\n",
    "        else:\n",
    "            all_colors[y_true_i].append(\"black\")\n",
    "        #all_colors[y_true_i].append(colors[y_pred_i])\n",
    "\n",
    "    all_x = [np.stack(x_list) for x_list in all_x]\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "        \n",
    "    for x_list, color_list, marker in zip(all_x, all_colors, markers):\n",
    "        ax.scatter(x_list[:, 0], x_list[:, 1], edgecolor=\"black\", marker=marker, facecolor=color_list, s=100)\n",
    "    \n",
    "        \n",
    "    xlim = (min([x_list[:,0].min() for x_list in all_x]), \n",
    "            max([x_list[:,0].max() for x_list in all_x]))\n",
    "            \n",
    "    ylim = (min([x_list[:,1].min() for x_list in all_x]), \n",
    "            max([x_list[:,1].max() for x_list in all_x]))\n",
    "            \n",
    "    # hyperplane\n",
    "    \n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        Z = perceptron(torch.tensor(xy, dtype=torch.float32), \n",
    "                       apply_softmax=True)\n",
    "        Z  = Z[:, i].data.numpy().reshape(XX.shape)\n",
    "        ax.contour(XX, YY, Z, colors=colors[i], levels=levels, linestyles=linestyles)\n",
    "    \n",
    "    # plotting niceties\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    if epoch is not None:\n",
    "        plt.text(xlim[0], ylim[1], \"Epoch = {}\".format(str(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 24\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "x_data, y_truth = get_toy_data(batch_size=1000)\n",
    "\n",
    "x_data = x_data.data.numpy()\n",
    "y_truth = y_truth.data.numpy().astype(np.int64)\n",
    "\n",
    "n_classes = len(set(LABELS))\n",
    "\n",
    "all_x = [[] for _ in range(n_classes)]\n",
    "all_colors = [[] for _ in range(n_classes)]\n",
    "\n",
    "colors = ['black', 'white']\n",
    "markers = ['o', '*']\n",
    "\n",
    "for x_i, y_true_i in zip(x_data, y_truth):\n",
    "    all_x[y_true_i].append(x_i)\n",
    "    all_colors[y_true_i].append(colors[y_true_i])\n",
    "\n",
    "all_x = [np.stack(x_list) for x_list in all_x]\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "\n",
    "for x_list, color_list, marker in zip(all_x, all_colors, markers):\n",
    "    ax.scatter(x_list[:, 0], x_list[:, 1], edgecolor='black', marker=marker, facecolor=\"white\", s=100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.title(\"\");\n",
    "\n",
    "plt.savefig(\"images/data.png\")\n",
    "plt.savefig(\"images/data.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Perceptron\n",
    "\n",
    "A perceptron is a multilayer perceptron.  To properly discuss it in this light, we will use the variable name `mlp1`.   We use the class above with `num_hidden_layers=0` to create the perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = len(set(LABELS))\n",
    "num_hidden_layers = 0\n",
    "hidden_size = 2 # isn't ever used but we still set it\n",
    "\n",
    "\n",
    "seed = 24\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "mlp1 = MultilayerPerceptron(input_size=input_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_hidden_layers=num_hidden_layers, \n",
    "                            output_size=output_size)\n",
    "print(mlp1)\n",
    "batch_size = 1000\n",
    "\n",
    "x_data_static, y_truth_static = get_toy_data(batch_size)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "visualize_results(mlp1, x_data_static, y_truth_static, \n",
    "                  ax=ax, title='Initial Perceptron State', levels=[0.5])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig('images/perceptron_initial.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "batch_size = 10000\n",
    "n_batches = 10\n",
    "max_epochs = 10\n",
    "\n",
    "loss_change = 1.0\n",
    "last_loss = 10.0\n",
    "change_threshold = 1e-3\n",
    "epoch = 0\n",
    "all_imagefiles = []\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(params=mlp1.parameters(), lr=lr)\n",
    "cross_ent_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def early_termination(loss_change, change_threshold, epoch, max_epochs):\n",
    "    terminate_for_loss_change = loss_change < change_threshold\n",
    "    terminate_for_epochs = epoch > max_epochs\n",
    "    \n",
    "    #return terminate_for_loss_change or \n",
    "    return terminate_for_epochs\n",
    "\n",
    "while not early_termination(loss_change, change_threshold, epoch, max_epochs):\n",
    "    for _ in range(n_batches):\n",
    "        # step 0: fetch the data\n",
    "        x_data, y_target = get_toy_data(batch_size)\n",
    " \n",
    "        # step 1: zero the gradients\n",
    "        mlp1.zero_grad()\n",
    "        \n",
    "        # step 2: run the forward pass\n",
    "        y_pred = mlp1(x_data).squeeze()\n",
    "        \n",
    "        # step 3: compute the loss\n",
    "        loss = cross_ent_loss(y_pred, y_target.long())\n",
    "\n",
    "        # step 4: compute the backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # step 5: have the optimizer take an optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # auxillary: bookkeeping\n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "        loss_change = abs(last_loss - loss_value)\n",
    "        last_loss = loss_value\n",
    "                \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "    visualize_results(mlp1, x_data_static, y_truth_static, ax=ax, epoch=epoch, \n",
    "                      title=f\"{loss_value:0.2f}; {loss_change:0.4f}\")\n",
    "    plt.axis('off')\n",
    "    epoch += 1\n",
    "    all_imagefiles.append(f'images/perceptron_epoch{epoch}_toylearning.png')\n",
    "    plt.savefig(all_imagefiles[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 2 layer Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = len(set(LABELS))\n",
    "num_hidden_layers = 1\n",
    "hidden_size = 2\n",
    "\n",
    "seed = 2\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "mlp2 = MultilayerPerceptron(input_size=input_size, \n",
    "                           hidden_size=hidden_size, \n",
    "                           num_hidden_layers=num_hidden_layers, \n",
    "                           output_size=output_size)\n",
    "print(mlp2)\n",
    "batch_size = 1000\n",
    "\n",
    "x_data_static, y_truth_static = get_toy_data(batch_size)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "visualize_results(mlp2, x_data_static, y_truth_static, \n",
    "                  ax=ax, title='Initial 2-Layer MLP State', levels=[0.5])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig('images/mlp2_initial.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "batch_size = 10000\n",
    "n_batches = 10\n",
    "max_epochs = 15\n",
    "\n",
    "loss_change = 1.0\n",
    "last_loss = 10.0\n",
    "change_threshold = 1e-5\n",
    "epoch = 0\n",
    "all_imagefiles = []\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(params=mlp2.parameters(), lr=lr)\n",
    "cross_ent_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def early_termination(loss_change, change_threshold, epoch, max_epochs):\n",
    "    terminate_for_loss_change = loss_change < change_threshold    \n",
    "    terminate_for_epochs = epoch > max_epochs\n",
    "    \n",
    "    #return terminate_for_loss_change or \n",
    "    return terminate_for_epochs\n",
    "\n",
    "while not early_termination(loss_change, change_threshold, epoch, max_epochs):\n",
    "    for _ in range(n_batches):\n",
    "        # step 0: fetch the data\n",
    "        x_data, y_target = get_toy_data(batch_size)\n",
    " \n",
    "        # step 1: zero the gradients\n",
    "        mlp2.zero_grad()\n",
    "        \n",
    "        # step 2: run the forward pass\n",
    "        y_pred = mlp2(x_data).squeeze()\n",
    "        \n",
    "        # step 3: compute the loss\n",
    "        loss = cross_ent_loss(y_pred, y_target.long())\n",
    "\n",
    "        # step 4: compute the backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # step 5: have the optimizer take an optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # auxillary: bookkeeping\n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "        loss_change = abs(last_loss - loss_value)\n",
    "        last_loss = loss_value\n",
    "                \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "    visualize_results(mlp2, x_data_static, y_truth_static, ax=ax, epoch=epoch, \n",
    "                      title=f\"{loss_value:0.2f}; {loss_change:0.4f}\")\n",
    "    plt.axis('off')\n",
    "    epoch += 1\n",
    "    all_imagefiles.append(f'images/mlp2_epoch{epoch}_toylearning.png')\n",
    "    plt.savefig(all_imagefiles[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 3 layer Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = len(set(LABELS))\n",
    "num_hidden_layers = 2\n",
    "hidden_size = 2\n",
    "\n",
    "seed = 399\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "mlp3 = MultilayerPerceptron(input_size=input_size, \n",
    "                           hidden_size=hidden_size, \n",
    "                           num_hidden_layers=num_hidden_layers, \n",
    "                           output_size=output_size)\n",
    "print(mlp3)\n",
    "batch_size = 1000\n",
    "\n",
    "x_data_static, y_truth_static = get_toy_data(batch_size)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "visualize_results(mlp3, x_data_static, y_truth_static, \n",
    "                  ax=ax, title='Initial 3-Layer MLP State', levels=[0.5])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig('images/mlp3_initial.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "batch_size = 10000\n",
    "n_batches = 10\n",
    "max_epochs = 10\n",
    "\n",
    "loss_change = 1.0\n",
    "last_loss = 10.0\n",
    "change_threshold = 1e-5\n",
    "epoch = 0\n",
    "all_imagefiles = []\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(params=mlp3.parameters(), lr=lr)\n",
    "cross_ent_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def early_termination(loss_change, change_threshold, epoch, max_epochs):\n",
    "    terminate_for_loss_change = loss_change < change_threshold    \n",
    "    terminate_for_epochs = epoch > max_epochs\n",
    "    \n",
    "    #return terminate_for_loss_change or \n",
    "    return terminate_for_epochs\n",
    "\n",
    "while not early_termination(loss_change, change_threshold, epoch, max_epochs):\n",
    "    for _ in range(n_batches):\n",
    "        # step 0: fetch the data\n",
    "        x_data, y_target = get_toy_data(batch_size)\n",
    " \n",
    "        # step 1: zero the gradients\n",
    "        mlp3.zero_grad()\n",
    "        \n",
    "        # step 2: run the forward pass\n",
    "        y_pred = mlp3(x_data).squeeze()\n",
    "        \n",
    "        # step 3: compute the loss\n",
    "        loss = cross_ent_loss(y_pred, y_target.long())\n",
    "\n",
    "        # step 4: compute the backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # step 5: have the optimizer take an optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # auxillary: bookkeeping\n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "        loss_change = abs(last_loss - loss_value)\n",
    "        last_loss = loss_value\n",
    "                \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "    visualize_results(mlp3, x_data_static, y_truth_static, ax=ax, epoch=epoch, \n",
    "                      title=f\"{loss_value:0.2f}; {loss_change:0.4f}\")\n",
    "    plt.axis('off')\n",
    "    epoch += 1\n",
    "    all_imagefiles.append(f'images/mlp3_epoch{epoch}_toylearning.png')\n",
    "    plt.savefig(all_imagefiles[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "visualize_results(mlp1, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=ax)\n",
    "plt.axis('off');\n",
    "plt.savefig('images/perceptron_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "visualize_results(mlp2, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=ax)\n",
    "plt.axis('off');\n",
    "plt.savefig('images/mlp2_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "visualize_results(mlp3, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=ax)\n",
    "plt.axis('off');\n",
    "plt.savefig('images/mlp3_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1,2,figsize=(12,5))\n",
    "visualize_results(mlp1, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[0])\n",
    "visualize_results(mlp2, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[1])\n",
    "plt.tight_layout()\n",
    "axes[0].axis('off');\n",
    "axes[1].axis('off');\n",
    "plt.savefig(\"images/perceptron_vs_mlp2.png\")\n",
    "plt.savefig(\"images/figure_4_3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1,2,figsize=(12,5))\n",
    "visualize_results(mlp1, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[0])\n",
    "visualize_results(mlp3, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[1])\n",
    "plt.tight_layout()\n",
    "axes[0].axis('off');\n",
    "axes[1].axis('off');\n",
    "plt.savefig(\"images/perceptron_vs_mlp3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1,3,figsize=(16,5))\n",
    "visualize_results(mlp1, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[0])\n",
    "visualize_results(mlp2, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[1])\n",
    "visualize_results(mlp3, x_data_static, y_truth_static, epoch=None, levels=[0.5], ax=axes[2])\n",
    "plt.tight_layout()\n",
    "axes[0].axis('off');\n",
    "axes[1].axis('off');\n",
    "axes[2].axis('off');\n",
    "plt.savefig(\"images/perceptron_vs_mlp2_vs_mlp3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intermediate_representations(mlp_model, plot_title, figsize=(10,2)):\n",
    "    x_data, y_target = get_toy_data(batch_size)\n",
    "\n",
    "    y_pred = mlp_model(x_data, True).detach().numpy()\n",
    "\n",
    "    x_data = x_data.numpy()\n",
    "    y_target = y_target.numpy()\n",
    "\n",
    "    colors = ['black', 'white'] \n",
    "    markers = ['o', '*'] \n",
    "\n",
    "    #     plot_colors = []\n",
    "    #     for i in range(y_target.shape[0]):\n",
    "    #         plot_colors.append(colors[y_target[i]])\n",
    "\n",
    "    plot_markers = []\n",
    "    class_zero_indices = []\n",
    "    class_one_indices = []\n",
    "    for i in range(y_target.shape[0]):\n",
    "        if y_target[i] == 0:\n",
    "            class_zero_indices.append(i)\n",
    "        else:\n",
    "            class_one_indices.append(i)\n",
    "    class_zero_indices = np.array(class_zero_indices)\n",
    "    class_one_indices = np.array(class_one_indices)\n",
    "    # plot_markers.append(markers[y_target[i]])\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(mlp_model.last_forward_cache), figsize=figsize)\n",
    "\n",
    "    for class_index, data_indices in enumerate([class_zero_indices, class_one_indices]):\n",
    "\n",
    "        axes[0].scatter(x_data[data_indices,0], x_data[data_indices,1], edgecolor='black', facecolor=\"white\",\n",
    "                            marker=markers[class_index], s=[200,400][class_index])\n",
    "        axes[0].axis('off')\n",
    "        for i, activations in enumerate(mlp_model.last_forward_cache[1:], 1):\n",
    "            axes[i].scatter(activations[data_indices,0], activations[data_indices,1], edgecolor='black', facecolor=\"white\",\n",
    "                            marker=markers[class_index], s=[200,400][class_index])\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.suptitle(plot_title, size=15)\n",
    "    plt.subplots_adjust(top=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_representations(mlp1, \n",
    "                                  \"The Perceptron's Input and Intermediate Representation\",\n",
    "                                  figsize=(9, 3))\n",
    "plt.savefig(\"images/perceptron_intermediate.png\")\n",
    "plt.savefig(\"images/figure_4_5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_representations(mlp2,\n",
    "                                  \"A 2-layer MLP's Input and Intermediate Representation\",\n",
    "                                  figsize=(10, 3))\n",
    "plt.savefig(\"images/mlp2_intermediate.png\")\n",
    "plt.savefig(\"images/figure_4_4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_representations(mlp3, \n",
    "                                  \"The 3-layer Multilayer Perceptron's Input and Intermediate Representation\",\n",
    "                                  figsize=(13, 3))\n",
    "plt.savefig(\"images/mlp3_intermediate.png\")\n",
    "plt.savefig(\"images/mlp3_intermediate.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch04",
   "language": "python",
   "name": "pytorch04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
